# Семинар 05 - Линейные модели, вероятности и честный ML-эксперимент

## 1. Место в курсе

Пятый семинар курса «Инженерия Искусственного Интеллекта».

Опирается на материалы лекций L03-L05 (метрики качества, линейные и логистические модели, вероятности и калибровка) и результаты семинаров S02-S04 (работа с табличными данными, EDA, инженерный Python-проект и HTTP-сервис качества датасетов).

Это первый семинар, где основное внимание уходит на **обучение и оценку моделей**:

- студенты вспоминают линейную регрессию в простом синтетическом примере;
- переходят к логистической регрессии как базовой модели для бинарной классификации;
- видят полный цикл честного ML-эксперимента: сплит на train/val, бейзлайн-модель, подбор гиперпараметров, метрики и калибровка вероятностей.

Домашнее задание по семинару – **HW05**, его формальное описание дано в файле `seminars/S05/S05-homework.md`.  
Семинар S05 логически связывает лекционный материал по линейным моделям с дальнейшими неделями, где модели будут уже интегрироваться в более сложные пайплайны и сервисы.

---

## 2. Цели семинара

После семинара и выполнения домашнего задания студент:

- понимает различие между задачей регрессии и классификации и почему **логистическая регрессия** лучше подходит для бинарной классификации, чем «линейка по 0/1»;
- умеет обучать и интерпретировать **линейную регрессию** и **логистическую регрессию** в `scikit-learn` на табличных данных;
- умеет строить и использовать **простые бейзлайны** (например, `DummyRegressor` / `DummyClassifier`) для сравнения с реальной моделью;
- может реализовать **минимальный честный ML-эксперимент**:
  - корректно разделить данные на train/val (или train/test);
  - подобрать гиперпараметры логистической регрессии (например, параметр регуляризации `C`);
  - оценить модель по нескольким метрикам (accuracy, ROC-AUC, PR-AUC, confusion matrix и т.п.);
- понимает идею **калибровки вероятностей** (зачем она нужна и чем «плохая» калибровка отличается от хорошей на интуитивных примерах);
- умеет сохранять результаты эксперимента (метрики, параметры, простые графики) в структуру репозитория так, чтобы ими можно было пользоваться дальше.

Отдельно подчёркивается, что **линеаризация признаков и SVM** в рамках S05 рассматриваются как **опциональный бонус для самостоятельного изучения** и не входят в основные цели семинара.

---

## 3. Краткое содержание

1. **Вступление и связь с предыдущими семинарами**
   - краткое напоминание, что на S02-S04 студенты учились:
     - работать с табличными данными и делать EDA;
     - оформлять код в виде проекта `eda-cli`;
     - поднимать HTTP-сервис качества датасетов;
   - постановка задач S05: перейти от анализа данных к **обучению и оценке моделей**, используя аккуратный экспериментальный цикл.

2. **Demo 1: Линейная регрессия и её ограничения**
   - синтетический пример (простая зависимость + шум) и обучение `LinearRegression` или градиентным спуском;
   - разбор того, как выглядит прямая на данных, как меняется ошибка;
   - переход к реальному датасету: где линейная модель начинает «ломаться»;
   - обсуждение: чем такая модель хороша, какие у неё ограничения и почему этого мало для классификации.

3. **Demo 2: Логистическая регрессия как модель для классификации**
   - постановка задачи бинарной классификации на табличных данных;
   - логистическая регрессия в `scikit-learn`:
     - разделяющая гиперплоскость;
     - интерпретация `predict_proba` и порога 0.5;
   - интуитивное объяснение, чем **прогноз вероятности класса** отличается от «прогноза числа 0/1 линейной регрессией»;
   - короткий обзор важности выбора метрик для несбалансированных задач.

4. **Demo 3: Честный ML-эксперимент, метрики и калибровка**
   - выбор датасета и таргета, подготовка признаков (минимально необходимая препроцессинга);
   - разбиение на train/val (или train/test);
   - бейзлайн-модель: `DummyClassifier` (например, предсказывает наиболее частый класс);
   - логистическая регрессия как основная модель:
     - использование `Pipeline` (препроцессинг + модель);
     - подбор параметра регуляризации `C` (например, `GridSearchCV`);
   - оценка модели по нескольким метрикам:
     - ROC-кривая и ROC-AUC;
     - PR-кривая и PR-AUC (для несбалансированных выборок);
     - confusion matrix и простые текстовые выводы;
   - простая демонстрация **калибровки вероятностей**:
     - визуальное сравнение «сырых» прогнозов и калиброванных (reliability plot / калибровочная кривая);
     - обсуждение, где это важно (например, в системах принятия решений и ранжировании).

5. **Оформление результатов**
   - обсуждение того, какие элементы эксперимента важно сохранять:
     - код обучения и оценки модели;
     - параметры (`C`, выбор признаков, размер сплита и т.п.);
     - ключевые метрики и краткие интерпретации;
     - минимальные визуализации (кривые ROC/PR, калибровка).

---

## 4. Формат проведения

Семинар проводится в формате, согласованном с общей политикой по семинарам:

- **Краткий разбор (начало занятия)**:
  - связь S05 с лекциями L03-L05 и предыдущими семинарами;
  - формулировка основных вопросов: «что такое честный ML-эксперимент» и «как минимально правильно оценивать простые модели».

- **Практическая часть (основное время, live-coding + обсуждение)**:
  - прохождение трёх ноутбуков-демонстраций:
    1. линейная регрессия на синтетике и реальном датасете;
    2. логистическая регрессия и вероятности;
    3. экспериментальный цикл + метрики + калибровка;
  - по ходу – мини-вопросы студентам:
    - чем отличаются задачи регрессии и классификации;
    - почему `DummyClassifier` важен как бейзлайн;
    - какие метрики уместны в разных сценариях.

- **Постановка домашнего задания HW05 (финал)**:
  - пояснение ожидаемой структуры `homeworks/HW05/`;
  - акцент на том, что в HW05 важно не только «обучить модель», но и:
    - корректно оформить эксперимент (разбиение, метрики, сохранение результатов);
    - кратко прокомментировать выводы;
  - ответы на вопросы по линейным моделям, метрикам и калибровке.

---

## 5. Результат для студента

К концу семинара студент:

- видит на практических примерах, как лекционные идеи про линейные и логистические модели превращаются в рабочий код и эксперименты;
- понимает роль бейзлайнов и корректной оценки качества модели;
- умеет настроить и оценить простейший, но честный ML-эксперимент с использованием `scikit-learn`.

После выполнения домашнего задания HW05 у студента:

- в репозитории есть папка `homeworks/HW05/` с:
  - основным ноутбуком `HW05.ipynb`, где:
    - загружен и проанализирован учебный датасет `S05-hw-dataset.csv` с бинарным таргетом `default`;
    - выделены признаки и таргет, выполнен train/test-сплит с фиксированным `random_state` (и, по возможности, `stratify`);
    - построен и интерпретирован простой бейзлайн на основе `DummyClassifier`;
    - обучена логистическая регрессия в виде `Pipeline` (например, `StandardScaler` + `LogisticRegression`) с подбором хотя бы одного гиперпараметра (`C`);
    - посчитаны и зафиксированы несколько метрик качества (как минимум `accuracy` и `ROC-AUC`) для бейзлайна и логистической регрессии;
    - построен и проинтерпретирован хотя бы один график (например, ROC-кривая);
    - сформулирован краткий текстовый отчёт с выводами по результатам эксперимента;
  - (опционально) дополнительными артефактами эксперимента (графики, таблицы с результатами, сохранённые параметры моделей);
- заложена база для дальнейших проектных экспериментов с более сложными моделями (деревья, ансамбли, SVM и т.п.), уже на фоне осознанного бейзлайна и честного экспериментального протокола.

---

## 6. Дополнительные материалы (опционально)

В дополнение к основным ноутбукам семинара предусмотрены **бонусные материалы**, которые студенты могут изучить самостоятельно:

- **Линеаризация признаков (feature engineering / полиномиальные признаки)**:
  - пример расширения признакового пространства (например, через полиномиальные комбинации признаков);
  - визуальная иллюстрация того, как «нелинейная» задача становится линейной в новом пространстве.

- **Краткий бонус по SVM**
  - демонстрация SVM в `scikit-learn` как ещё одной линейной модели в другом пространстве признаков;
  - простое сравнение с логистической регрессией на небольшом датасете.

Эти материалы **не входят в обязательную часть S05** и **не проверяются в HW05** напрямую, но могут помочь глубже понять связь между линейными моделями, линеаризацией и SVM.
